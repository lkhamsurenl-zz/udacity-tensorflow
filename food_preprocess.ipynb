{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning food categories reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load(data_folders, min_num_images, max_num_images):\n",
    "  dataset = np.ndarray(\n",
    "    shape=(max_num_images, image_size, image_size), dtype=np.float32)\n",
    "  labels = np.ndarray(shape=(max_num_images), dtype=np.int32)\n",
    "  label_index = 0\n",
    "  image_index = 0\n",
    "  for folder in data_folders:\n",
    "    print folder\n",
    "    for image in os.listdir(folder):\n",
    "      if image_index >= max_num_images:\n",
    "        raise Exception('More images than expected: %d >= %d' % (\n",
    "          num_images, max_num_images))\n",
    "      image_file = os.path.join(folder, image)\n",
    "      try:\n",
    "        image_data = (ndimage.imread(image_file).astype(float) -\n",
    "                      pixel_depth / 2) / pixel_depth\n",
    "        if image_data.shape != (image_size, image_size):\n",
    "          raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "        dataset[image_index, :, :] = image_data\n",
    "        labels[image_index] = label_index\n",
    "        image_index += 1\n",
    "      except IOError as e:\n",
    "        print 'Could not read:', image_file, ':', e, '- it\\'s ok, skipping.'\n",
    "    label_index += 1\n",
    "  num_images = image_index\n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  labels = labels[0:num_images]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' % (\n",
    "        num_images, min_num_images))\n",
    "  print 'Full dataset tensor:', dataset.shape\n",
    "  print 'Mean:', np.mean(dataset)\n",
    "  print 'Standard deviation:', np.std(dataset)\n",
    "  print 'Labels:', labels.shape\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = load(train_folders, 450000, 550000)\n",
    "test_dataset, test_labels = load(test_folders, 18000, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the dataset so that it's not skewed in only one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(133)\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation set data and test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "\n",
    "valid_dataset = train_dataset[:valid_size,:,:]\n",
    "valid_labels = train_labels[:valid_size]\n",
    "train_dataset = train_dataset[valid_size:valid_size+train_size,:,:]\n",
    "train_labels = train_labels[valid_size:valid_size+train_size]\n",
    "print 'Training', train_dataset.shape, train_labels.shape\n",
    "print 'Validation', valid_dataset.shape, valid_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pickle so that can be easily loaded later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'foods.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print 'Unable to save data to', pickle_file, ':', e\n",
    "  raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
